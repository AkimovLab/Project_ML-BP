#!/bin/sh
###SBATCH --partition=scavenger  --qos=scavenger
###SBATCH --clusters=faculty
###SBATCH --partition=debug  --qos=debug
#SBATCH --partition=general-compute  --qos=general-compute
###SBATCH --clusters=faculty
#SBATCH --time=24:00:00
#SBATCH --nodes=1
#SBATCH --requeue
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=48000
###SBATCH --mail-user=alexeyak@buffalo.edu
echo "SLURM_JOBID="$SLURM_JOBID
echo "SLURM_JOB_NODELIST="$SLURM_JOB_NODELIST
echo "SLURM_NNODES="$SLURM_NNODES
echo "SLURMTMPDIR="$SLURMTMPDIR
echo "working directory="$SLURM_SUBMIT_DIR


module load cuda/6.5
module load vmd/v1.9
module load cp2k
module load jupyter
eval "$(/projects/academic/cyberwksp21/Software/Conda/Miniconda3/bin/conda shell.bash hook)"
conda activate libra


#module load openmpi/3.0.3/gcc-7.3.0
export I_MPI_PMI_LIBRARY=/usr/lib64/libpmi.so

if [ -n "$SLURM_CPUS_PER_TASK" ]; then
  omp_threads=$SLURM_CPUS_PER_TASK
else
  omp_threads=1
fi
export OMP_NUM_THREADS=$omp_threads



python nacs.py > o


